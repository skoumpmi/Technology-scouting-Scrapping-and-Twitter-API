# -*- coding: utf-8 -*-
"""bert.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12046nGLKAABbesZN0qzlbdUWrIsXHAeu
"""

# from google.colab import drive
# drive.mount('/content/drive')

# ! pip install pytorch-transformers
#
# LOCAL_FOLDER='drive/My Drive/Colab_Notebooks/BERT'
# import sys
# sys.path.append(LOCAL_FOLDER)
from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)
#from pytorch_transformers.optimization import AdamW, WarmupLinearSchedule
from sklearn.metrics import matthews_corrcoef, confusion_matrix
from bert_classifiers import linearClassifier, cnnClassifier
from torch.nn import CrossEntropyLoss
from sklearn.metrics import roc_curve
from tqdm import tqdm, trange
from logger import Logger
from tools import *
from utils import *
import pandas as pd
import numpy as np
import argparse
import warnings
import logging
import pickle
import torch
import time
import os
tqdm.pandas(desc='Progress', position=0, leave=True)
warnings.simplefilter(action='ignore', category=FutureWarning)
logging.basicConfig(level=logging.INFO)

from sklearn import metrics
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# def get_eval_report(task_name, labels, preds):
#     mcc = matthews_corrcoef(labels, preds)
#     tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()
#     return {
#         "task": task_name,
#         "mcc": mcc,
#         "tp": tp,
#         "tn": tn,
#         "fp": fp,
#         "fn": fn
#     }
#
# def compute_metrics(task_name, labels, preds):
#     assert len(preds) == len(labels)
#     return get_eval_report(task_name, labels, preds)

# def categorical_accuracy(preds, y):
#     """
#     Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8
#     """
#
#     # max_preds = preds.argmax(dim=1, keepdim=True)  # get the index of the max probability
#     max_preds, max_preds_index = preds.max(dim=1)
#     correct = max_preds_index.eq(y)
#     if FLAGS.gpu_enabled:
#         # DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#         result = correct.sum().to(dtype=torch.float) / torch.cuda.LongTensor([y.shape[0]]).to(dtype=torch.float)
#     else:
#         result = correct.sum().to(dtype=torch.float) / torch.LongTensor([y.shape[0]]).to(dtype=torch.float)
#     return result, max_preds, max_preds_index

def plotConfusionMatrix(test_y, y_pred, title="Confusion Matrix"):
    plt.figure()
    confusionMatrix = metrics.confusion_matrix(test_y, y_pred)
    print(confusionMatrix)
    cm_norm = confusionMatrix.astype('float') / confusionMatrix.sum(axis=1)[:, np.newaxis]
    print(cm_norm)
    sns.heatmap(cm_norm, annot=True, cbar=False, fmt = '.2f', cmap = 'Oranges')
    plt.title(title)
    plt.xlabel('True output' )
    plt.ylabel('Predicted output')
    plt.show()

def create_optimizer(model):

    param_optimizer = list(model.named_parameters())
    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']
    optimizer_grouped_parameters = [
        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},
        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}
    ]

    optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE)
    if FLAGS.restore_point:
        optimizer=load_bert_check_point_optimizer(optimizer, FLAGS.restore_point, OUTPUT_FOLDER)

    return optimizer

def create_scheduler(optimizer, num_train_optimization_steps):

    # scheduler = WarmupLinearSchedule(optimizer, warmup_steps=WARM_UP_STEPS,
    #                                  t_total=num_train_optimization_steps)  # PyTorch scheduler

    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARM_UP_STEPS,
                                     num_training_steps=num_train_optimization_steps)  # PyTorch scheduler
    get_linear_schedule_with_warmup

    if FLAGS.restore_point:
        scheduler = load_bert_check_point_scheduler(scheduler, FLAGS.restore_point, OUTPUT_FOLDER)

    return scheduler

def create_model(num_labels):

    start_epoch=1
    if FLAGS.classifier_type == 'MLP':
        print('MLP classifier')
        if FLAGS.restore_point:
            logger.info("Restore point: {0}".format(FLAGS.restore_point))
            model_state_dict, start_epoch=load_bert_check_point_model(restore_point=FLAGS.restore_point,
                                                            output_folder=OUTPUT_FOLDER,
                                                            model_type=None)
            cache_dir = os.path.join(OUTPUT_FOLDER, FLAGS.restore_point)
            model = linearClassifier.from_pretrained(BERT_MODEL,    cache_dir=CACHE_DIR,
                                                                    state_dict=model_state_dict,
                                                                    num_labels=num_labels)
            #model.train()
        else:
            model = linearClassifier.from_pretrained(BERT_MODEL, cache_dir=CACHE_DIR, num_labels=num_labels)

    elif FLAGS.classifier_type == 'CNN':
        model = cnnClassifier.from_pretrained(BERT_MODEL,
                                              cache_dir=CACHE_DIR,
                                              num_labels=num_labels,
                                              n_filters=100,
                                              filter_sizes=[3, 4, 5],
                                              output_dim=num_labels)
    if not FLAGS.model_finetune:
        model.freeze_bert_encoder()

    model.to(DEVICE)

    return model, start_epoch

def train(model, train_dataloader, optimizer, scheduler, num_labels):

    epoch_loss = 0
    epoch_acc = 0
    y_true = []
    y_score = []

    model.train()
    for step, batch in enumerate(tqdm(train_dataloader, desc="Iteration", leave=True, position=0)):

        batch = tuple(t.to(DEVICE) for t in batch)
        input_ids, input_mask, segment_ids, label_ids = batch

        outputs = model(input_ids, segment_ids, input_mask, labels=None)
        logits = outputs[0]

        loss_fct = CrossEntropyLoss()
        predictions = logits.view(-1, num_labels)
        gnd = label_ids.view(-1)
        loss = loss_fct(predictions, gnd)
        acc, max_preds, max_preds_index = categorical_accuracy(predictions, gnd, DEVICE)

        if GRADIENT_ACCUMULATION_STEPS > 1:
            loss = loss / GRADIENT_ACCUMULATION_STEPS

        loss.backward()

        epoch_loss += loss.item()
        epoch_acc += acc.item()

        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:
            optimizer.step()
            scheduler.step()  # ADDED!!
            optimizer.zero_grad()
            # global_step += 1

        y_true.extend(gnd.cpu().data.numpy().astype(np.float32))
        y_score.extend(max_preds_index.cpu().data.numpy().astype(np.float32))

    roc_auc = multiclass_roc_score(y_true, y_score, average="macro")

    return epoch_loss / len(train_dataloader), epoch_acc / len(train_dataloader), roc_auc

def evaluate(model, eval_dataloader, num_labels):

    if not eval_dataloader:
        return None, None, None

    epoch_loss = 0
    epoch_acc = 0
    y_true = []
    y_score = []

    model.eval()

    with torch.no_grad():
        for input_ids, input_mask, segment_ids, label_ids in tqdm(eval_dataloader,
                                                                  desc="Evaluating",
                                                                  leave=True, position=0):
            input_ids = input_ids.to(DEVICE)
            input_mask = input_mask.to(DEVICE)
            segment_ids = segment_ids.to(DEVICE)
            label_ids = label_ids.to(DEVICE)

            # logits = model(input_ids, segment_ids, input_mask, labels=None)
            outputs = model(input_ids, segment_ids, input_mask, labels=None)
            logits = outputs[0]

            # create eval loss and other metric required by the task
            loss_fct = CrossEntropyLoss()
            predictions = logits.view(-1, num_labels)
            gnd = label_ids.view(-1)
            loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))

            acc, max_preds, max_preds_index = categorical_accuracy(predictions, gnd, DEVICE)

            epoch_loss += loss.mean().item()
            epoch_acc += acc.item()

            y_true.extend(gnd.cpu().data.numpy().astype(np.float32))
            y_score.extend(max_preds_index.cpu().data.numpy().astype(np.float32))


    # Confusion Matrix
    # conf_mat = confusion_matrix(y_true, y_score)
    # conf_mat_df = pd.DataFrame(conf_mat)
    # conf_mat_df.to_csv('conf_mat_df.csv')

    # plotConfusionMatrix(y_true, y_score)


    # Compute fpr, tpr, thresholds and roc auc
    #fpr, tpr, thresholds = roc_curve(y_true, y_score)
    roc_auc = multiclass_roc_score(y_true, y_score, average="macro")

    #auc_stats = {"fpr": fpr.tolist(), "tpr": tpr.tolist(), "thresholds": thresholds.tolist(), "roc_auc": roc_auc}

    return epoch_loss / len(eval_dataloader), epoch_acc / len(eval_dataloader), roc_auc

def fit_model(model, train_dataloader, eval_dataloader, test_dataloader, optimizer,
              scheduler, num_labels, start_epoch=1, save_model=False):

    train_loss_logger = Logger(os.path.join(LOG_FOLDER, 'train_logs'))
    train_acc_logger = Logger(os.path.join(LOG_FOLDER, 'train_acc'))
    train_auc_score_logger = Logger(os.path.join(LOG_FOLDER, "train_auc_score"))

    if eval_dataloader:
        val_loss_logger = Logger(os.path.join(LOG_FOLDER, 'val_logs'))
        val_acc_logger = Logger(os.path.join(LOG_FOLDER, 'val_acc'))
        val_auc_score_logger = Logger(os.path.join(LOG_FOLDER, "val_auc_score"))

    if test_dataloader:
        test_loss_logger = Logger(os.path.join(LOG_FOLDER, 'test_logs'))
        test_acc_logger = Logger(os.path.join(LOG_FOLDER, 'test_acc'))
        test_auc_score_logger = Logger(os.path.join(LOG_FOLDER, "test_auc_score"))

    for epoch in trange(int(start_epoch), int(FLAGS.num_train_epochs), desc="Epoch"):

        start_time = time.time()
        train_loss, train_acc, train_roc_auc = train(model=model,
                                      train_dataloader=train_dataloader,
                                      optimizer=optimizer,
                                      scheduler=scheduler,
                                      num_labels=num_labels)

        valid_loss, valid_acc, valid_roc_auc = evaluate(model=model,
                                                 eval_dataloader=eval_dataloader,
                                                 num_labels=num_labels)

        test_loss, test_acc, test_roc_auc = evaluate(model=model,
                                               eval_dataloader=test_dataloader,
                                               num_labels=num_labels)

        end_time = time.time()
        epoch_mins, epoch_secs = epoch_time(start_time, end_time)
        print(f'Epoch: {epoch:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')

        # ============ TensorBoard logging ============#
        # Log the scalar values
        train_loss_info = {'loss': train_loss}
        train_acc_info = {'accuracy': train_acc * 100}
        train_auc_info = {'AUC': train_roc_auc}

        for tag, value in train_acc_info.items(): train_acc_logger.scalar_summary(tag, value, step=epoch)
        for tag, value in train_loss_info.items(): train_loss_logger.scalar_summary(tag, value, step=epoch)
        for tag, value in train_auc_info.items(): train_auc_score_logger.scalar_summary(tag, value, step=epoch)

        print(f'\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}% | Train. AUC: {train_roc_auc:.4f}')

        if eval_dataloader:
            val_loss_info = {'loss': valid_loss}
            val_acc_info = {'accuracy': valid_acc * 100}
            val_roc_auc_info = {'AUC': valid_roc_auc}
            for tag, value in val_acc_info.items(): val_acc_logger.scalar_summary(tag, value, step=epoch)
            for tag, value in val_loss_info.items(): val_loss_logger.scalar_summary(tag, value, step=epoch)
            for tag, value in val_roc_auc_info.items(): val_auc_score_logger.scalar_summary(tag, value, step=epoch)

            print(f'\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.3f}% | Val. AUC: {valid_roc_auc:.4f}')

        if test_dataloader:
            test_loss_info = {'loss': test_loss}
            test_acc_info = {'accuracy': test_acc * 100}
            test_roc_auc_info = {'AUC': test_roc_auc}
            for tag, value in test_acc_info.items(): test_acc_logger.scalar_summary(tag, value, step=epoch)
            for tag, value in test_loss_info.items(): test_loss_logger.scalar_summary(tag, value, step=epoch)
            for tag, value in test_roc_auc_info.items(): test_auc_score_logger.scalar_summary(tag, value, step=epoch)

            print(f'\t Test. Loss: {test_loss:.3f} |  Test. Acc: {test_acc * 100:.3f}% | Test. AUC: {test_roc_auc:.4f}')

        save_bert_checkpoint(model=model,
                            optimizer=optimizer,
                            scheduler=scheduler,
                            epoch=epoch,
                            output_folder=OUTPUT_FOLDER)

def load_featrures(file_name):

    try:
        file_path=os.path.join(DATA_DIR, file_name)
        print('==> Load file_path {0}'.format(file_path))
        with open(file_path, "rb") as f:
            features = pickle.load(f)
    except OSError:
        dataloader, train_examples_len, num_labels=None, None, None
        return dataloader, train_examples_len, num_labels

    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)
    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)
    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)

    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)

    data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)
    sampler = RandomSampler(data)
    dataloader = DataLoader(data, sampler=sampler, batch_size=TRAIN_BATCH_SIZE)

    train_examples_len = len(features)
    num_labels = len(np.unique(all_label_ids))

    return dataloader, train_examples_len, num_labels

def main():

    train_file = "train_features_{0}.pkl".format(FLAGS.task_name)
    test_file = "test_features_{0}.pkl".format(FLAGS.task_name)
    eval_file = "eval_features_{0}.pkl".format(FLAGS.task_name)

    train_dataloader, train_examples_len, num_labels = load_featrures(train_file)
    eval_dataloader, eval_examples_len, _ = load_featrures(eval_file)
    test_dataloader, test_examples_len, _ = load_featrures(test_file)

    if not train_dataloader:
        raise ValueError('Train data not found!')

    num_train_optimization_steps = int(
        train_examples_len / TRAIN_BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS) * FLAGS.num_train_epochs

    model, start_epoch = create_model(num_labels=num_labels)
    optimizer = create_optimizer(model=model)
    scheduler = create_scheduler(optimizer=optimizer, num_train_optimization_steps=num_train_optimization_steps)

    logger.info("***** Training Model *****")
    logger.info("  Batch size = %d", TRAIN_BATCH_SIZE)
    logger.info("  Num steps = %d", num_train_optimization_steps)
    logger.info("  Num steps = %d", num_train_optimization_steps)
    logger.info(" Num of training examples = %d", train_examples_len)
    if eval_dataloader: logger.info(" Num of eval examples = %d", eval_examples_len)
    if test_dataloader: logger.info(" Num of test examples = %d", test_examples_len)

    fit_model(model=model,
              start_epoch=start_epoch,
              train_dataloader=train_dataloader,
              eval_dataloader=eval_dataloader,
              test_dataloader=test_dataloader,
              optimizer=optimizer,
              scheduler=scheduler,
              num_labels=num_labels,
              save_model=FLAGS.save_model)
    
    # ------????????????????????????????????????
    # data_to_csv(data=data, 
    #            file_name="C:/Users/annak/Desktop/cleanBERT/cache/.data/imdb/aclImdb/train/urls_neg.txt", 
    #            label_field=" ")

    print('MAIN ENDED')

if __name__ == "__main__":

    TRAIN_BATCH_SIZE = 24
    EVAL_BATCH_SIZE = 8
    LEARNING_RATE = 2e-5
    RANDOM_SEED = 42
    GRADIENT_ACCUMULATION_STEPS = 1
    WARMUP_PROPORTION = 0.1
    WARM_UP_STEPS = 100

    parser = argparse.ArgumentParser()

    ### Required parameters
    parser.add_argument("--num_train_epochs", default=3.0, type=float,
                        help="Total number of training epochs to perform.")
    parser.add_argument("--task_name", default=None, type=str, required=True,
                        help="The name of the task to train")
    parser.add_argument("--main_path", type=str, default='./', required=False,
                        help="The main path where all files will be stored.")
    parser.add_argument("--classifier_type", type=str, default='MLP',
                        help="The name of the dataset for experimentation.")
    parser.add_argument("--save_model", type=str2bool, default=True, required=True,
                        help="Make or not checkpoints.")
    parser.add_argument("--model_finetune", type=str2bool, default=True, required=True,
                        help="Finetune or not the model.")
    parser.add_argument("--gpu_enabled", type=str2bool, default=True, required=False,
                        help="To run in gpu or not.")
    parser.add_argument("--restore_point", type=str, default='', required=False,
                        help="Continue model execution.")

    FLAGS = parser.parse_args()
    logger.info("num_train_epochs = %d", FLAGS.num_train_epochs)
    logger.info("task_name = %s", FLAGS.task_name)
    logger.info("main_path = %s", FLAGS.main_path)
    logger.info("classifier_type = %s", FLAGS.classifier_type)
    logger.info("save_model = %s", FLAGS.save_model)
    logger.info("model_finetune = %s", FLAGS.model_finetune)
    logger.info("gpu_enabled = %d", FLAGS.gpu_enabled)

    if FLAGS.gpu_enabled:
        # DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        DEVICE = torch.device("cuda")
    else:
        DEVICE = torch.device("cpu")

    logger.info('DEVICE USED: {0}'.format(DEVICE))

    main_DATA_DIR = os.path.join(FLAGS.main_path, "cache", ".data")
    # The input data dir. Should contain the .tsv files (or other data files) for the task.
    if FLAGS.task_name == 'sst-2-glue':
        DATA_DIR = os.path.join(main_DATA_DIR, "sst-2-glue")
        # The name of the task to train. I'm going to name this 'sst2'.
        TASK_NAME = 'sst-2-glue'
    elif FLAGS.task_name == 'sst-2-standard':
        DATA_DIR = os.path.join(main_DATA_DIR, "sst-2-standard")
        # The name of the task to train. I'm going to name this 'sst2'.
        TASK_NAME = 'sst-2-standard'
    elif FLAGS.task_name == 'sst-5-standard':
        DATA_DIR = os.path.join(main_DATA_DIR, "sst-5-standard")
        # The name of the task to train. I'm going to name this 'sst2'.
        TASK_NAME = 'sst-5-standard'
    elif FLAGS.task_name == 'yelp':
        DATA_DIR = os.path.join(main_DATA_DIR, "yelp")
        # The name of the task to train.I'm going to name this 'yelp'.
        TASK_NAME = 'yelp'
    elif FLAGS.task_name == 'imdb':
        DATA_DIR = os.path.join(main_DATA_DIR, "imdb")
        # The name of the task to train.I'm going to name this 'yelp'.
        TASK_NAME = 'imdb'
    elif FLAGS.task_name == 'MR':
        DATA_DIR = os.path.join(main_DATA_DIR, "MR")
        # The name of the task to train.I'm going to name this 'yelp'.
        TASK_NAME = 'MR'
    else:
        raise ValueError("Task name {0} does not exist".format(FLAGS.task_name))
    # Bert pre-trained model selected in the list: bert-base-uncased,
    # bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased,
    # bert-base-multilingual-cased, bert-base-chinese.
    BERT_MODEL = 'bert-base-cased'
    if FLAGS.model_finetune:
        OUTPUT_FOLDER = os.path.join(FLAGS.main_path, 'bert_outputs', 'fine_tuned', TASK_NAME )
    else:
        OUTPUT_FOLDER = os.path.join(FLAGS.main_path, 'bert_outputs', 'not_fine_tuned', TASK_NAME )
    CACHE_DIR = os.path.join(FLAGS.main_path, 'cache/bert_model')
    LOG_FOLDER = os.path.join(OUTPUT_FOLDER, "summaries")

    # The maximum total input sequence length after WordPiece tokenization.
    # Sequences longer than this will be truncated, and sequences shorter than this will be padded.
    MAX_SEQ_LENGTH = 128

    OUTPUT_MODE = 'classification'
    CONFIG_NAME = "config.json"
    MODEL_NAME = "pytorch_model.bin"

    if not os.path.exists(OUTPUT_FOLDER):
        os.makedirs(OUTPUT_FOLDER)

    if not os.path.exists(CACHE_DIR):
        os.makedirs(CACHE_DIR)

    if not os.path.exists(LOG_FOLDER):
        os.makedirs(LOG_FOLDER)

    print('--------------------------------------')
    print("OUTPUT_FOLDER {0}".format(OUTPUT_FOLDER))
    print("CACHE_DIR {0}".format(CACHE_DIR))
    print("LOG_FOLDER {0}".format(LOG_FOLDER))
    print('--------------------------------------')

    main()